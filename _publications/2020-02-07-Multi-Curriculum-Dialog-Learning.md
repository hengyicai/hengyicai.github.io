---
title: "Learning from Easy to Complex: Adaptive Multi-curricula Learning for Neural Dialogue Generation"
collection: publications
permalink: /publication/2020-02-07-Multi-Curriculum-Dialog-Learning
# excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2020-02-07
venue: 'AAAI'
paperurl: 'https://arxiv.org/abs/2003.00639'
citation: 'Hengyi Cai, Hongshen Chen, Cheng Zhang, Yonghao Song, Xiaofang Zhao, Yangxi Li, Dongsheng Duan and Dawei Yin. Learning from Easy to Complex: Adaptive Multi-curricula Learning for Neural Dialogue Generation. In Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI 2020), New York, USA, Feb. 2020.'
---

**Abstract**: Current state-of-the-art neural dialogue systems are mainly data-driven and are trained on human-generated responses. However, due to the subjectivity and open-ended nature of human conversations, the complexity of training dialogues varies greatly. The noise and uneven complexity of query-response pairs impede the learning efficiency and effects of the neural dialogue generation models. What is more, so far, there are no unified dialogue complexity measurements, and the dialogue complexity embodies multiple aspects of attributes---specificity, repetitiveness, relevance, etc. Inspired by human behaviors of learning to converse, where children learn from easy dialogues to complex ones and dynamically adjust their learning progress, in this paper, we first analyze five dialogue attributes to measure the dialogue complexity in multiple perspectives on three publicly available corpora. Then, we propose an adaptive multi-curricula learning framework to schedule a committee of the organized curricula. The framework is established upon the reinforcement learning paradigm, which automatically chooses different curricula at the evolving learning process according to the learning status of the neural dialogue generation model. Extensive experiments conducted on five state-of-the-art models demonstrate its learning efficiency and effectiveness with respect to 13 automatic evaluation metrics and human judgments.

<!-- **Motivation**:
-   Training data for neural dialogue models are quite noisy.
-   Learn from clean and easy samples first, and then gradually increase the data complexity. (The spirits of curriculum learning)
-   Organize the curriculum in terms of multiple empirical attributes---specificity, repetitiveness, relevance, etc. -->

<!-- [Download paper here](https://arxiv.org/abs/2003.00639) -->

<!-- Recommended citation: Hengyi Cai, Hongshen Chen, Cheng Zhang, Yonghao Song, Xiaofang Zhao, Yangxi Li, Dongsheng Duan and Dawei Yin.Learning from Easy to Complex: Adaptive Multi-curricula Learning for Neural Dialogue Generation. In Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI 2020), New York, USA, Feb. 2020. -->

